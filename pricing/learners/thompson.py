
from Learner import *
import numpy as np

class Thomspon(Learner):

  def __init__(self,n_arms):
    super().__init__(n_arms)
    self.beta_parameters=np.ones(n_arms,2)

  def pull_arm(self):
    idx=np.argmax(np.random.beta(self.beta_parameters[:,0],self.beta_parameters[:,1]))
    return idx

  def update(self, pulled_arm, reward):
    self.t+=1
    self.update_observations(pulled_arm, reward)
    self.beta_parameters[pulled_arm,0]=self.beta_parameters[pulled_arm,0]+reward
    self.beta_parameters[pulled_arm,1]=self.beta_parameters[pulled_arm,1]+1-reward



class SW_Thompson(Thompson):
  def __init__(self, n_arms, window_size):
    super().__init__(n_arms)
    self.window_size=window_size
    self.pulled_arms=np.array([])

  def update(self, pulled_arm, reward):
    self.t+=1
    self.update_observations(pulled_arm, reward)
    self.pulled_arms= np.append(self.pulled_arms, pulled_arm)
    for arm in range(self.n_arms):
      n_samples=np.sum(self.pulled_arms[-self.window_size:]==arm)
      cum_rew=np.sum(self.rewards_per_arm[arm][-n_samples:]) if n_samples>0 else 0
      self.beta_parameters[arm,0]=cum_rew+1.0
      self.beta_parameters[arm,1]=n_samples-cum_rew+1

